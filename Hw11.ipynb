{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Романов\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import pad_sequences, set_random_seed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, LSTM, Bidirectional, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Встановлюємо гіперпараметри"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000  # кількість слів, що розглядаються як особливості\n",
    "maxlen = 500  # обмеження кількості слів в тексті\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завантаження даних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "# Завантаження тренувальних та тестових даних зі вказанням обмеження на кількість слів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Опис датасету IMDB\n",
    "\n",
    "Датасет IMDB являє собою набір відгуків про фільми з сайту Internet Movie Database (IMDB). \n",
    "\n",
    "1. Дані (`input`): Це послідовності індексів слів, що представляють тексти відгуків про фільми. Кожен елемент у датасеті являє собою один відгук. Наприклад, `train_data[0]` містить послідовність індексів для першого відгуку.\n",
    "2. Мітки (`y`): Це бінарні значення (`0` або `1`), що представляють собою негативний або позитивний відгук. Наприклад, `train_labels[0]` містить мітку (`0` або `1`) для першого відгуку, вказуючи на те, негативний це відгук чи позитивний.\n",
    "\n",
    "Приклади:\n",
    "\n",
    "`train_data[0]`: `[1, 14, 22, 16, 43, ...]` (послідовність індексів слів першого відгуку)\n",
    "train_labels[0]: 1 (мітка, що вказує на позитивний відгук)\n",
    "\n",
    "Для декодування цих індексів назад у слова, можна використати словник `imdb.get_word_index()`, що надається `Keras`. \n",
    "\n",
    "\n",
    "\n",
    "## Розміри датасета\n",
    "\n",
    "\n",
    "### Тренувальний датасет:\n",
    "Розмір тренувальних даних: `(25000,)`\n",
    "Розмір міток тренувальних даних: `(25000,)`\n",
    "\n",
    "### Тестовий датасет:\n",
    "Розмір тестових даних: `(25000,)`\n",
    "Розмір міток тестових даних: `(25000,)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Декодуємо відгук\n",
    "\n",
    "\n",
    "def decode_review(numberlist: list):\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k: (v + 3) for k, v in word_to_id.items()}\n",
    "    # word_to_id[\"<PAD>\"] = 0\n",
    "    # word_to_id[\"<START>\"] = 1\n",
    "    # word_to_id[\"<UNK>\"] = 2\n",
    "    # word_to_id[\"<UNUSED>\"] = 3\n",
    "    word_to_id = {v: k for k, v in word_to_id.items()}\n",
    "    id_to_word = [\n",
    "        word_to_id.get(word) for word in numberlist if word not in range(0, 3)\n",
    "    ]\n",
    "    return \" \".join(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відгук: [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "Декодований: big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal the hair is big lots of boobs men wear those cut shirts that show off their sickening that men actually wore them and the music is just trash that plays over and over again in almost every scene there is trashy music boobs and taking away bodies and the gym still doesn't close for all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "Мітка: 0\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(f\"Відгук: {input_train[index]}\")\n",
    "print(f\"Декодований: {decode_review(input_train[index])}\")\n",
    "print(f\"Мітка: {y_train[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Передпроцесинг послідовних даних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(input_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(input_test, maxlen=maxlen)\n",
    "# Застосування заздалегідь обраної максимальної довжини до послідовних даних тренувального та тестового наборів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Побудова моделей\n",
    "\n",
    "1. [SimpleRNN layer](https://keras.io/api/layers/recurrent_layers/simple_rnn/)\n",
    "2. [LSTM layer](https://keras.io/api/layers/recurrent_layers/lstm/)\n",
    "\n",
    "Для порівняння моделі створимо з однаковим числом шарів, та з однаковими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self, name, max_features, layer):\n",
    "        self.name = name\n",
    "        self.max_features = max_features\n",
    "        self.build = self.build_model(layer)\n",
    "\n",
    "    def build_model(self, layers: list):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(self.max_features, 64))\n",
    "        for layer in layers:\n",
    "            model.add(layer)\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "        return model\n",
    "\n",
    "\n",
    "class SimpleRNNModel(BaseModel):\n",
    "    def __init__(self, name=\"SRNN\", max_features=max_features):\n",
    "        super().__init__(name, max_features, [SimpleRNN(units=64)])\n",
    "\n",
    "\n",
    "class LSTMModel(BaseModel):\n",
    "    def __init__(self, name=\"LSTM\", max_features=max_features):\n",
    "        super().__init__(name, max_features, [LSTM(units=64)])\n",
    "\n",
    "\n",
    "class BidirectionalRNNModel(BaseModel):\n",
    "    def __init__(self, name=\"Bidirectional_SRNN\", max_features=max_features):\n",
    "        super().__init__(name, max_features, [Bidirectional(SimpleRNN(units=64))])\n",
    "\n",
    "\n",
    "class BidirectionalLSTMModel(BaseModel):\n",
    "    def __init__(self, name=\"Bidirectional_LSTM\", max_features=max_features):\n",
    "        super().__init__(\n",
    "            name,\n",
    "            max_features,\n",
    "            [\n",
    "                Bidirectional(LSTM(units=64)),\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Створення моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Романов\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:130: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Романов\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for model_class in [\n",
    "    SimpleRNNModel,\n",
    "    BidirectionalRNNModel,\n",
    "    LSTMModel,\n",
    "    BidirectionalLSTMModel,\n",
    "]:\n",
    "    model_instance = model_class()\n",
    "    models.append(model_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Навчання моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 2**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start learning model: SRNN\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          640000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 648321 (2.47 MB)\n",
      "Trainable params: 648321 (2.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\Романов\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Романов\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "274/274 [==============================] - 66s 233ms/step - loss: 0.6598 - acc: 0.5845 - val_loss: 0.5049 - val_acc: 0.7683\n",
      "Epoch 2/5\n",
      "274/274 [==============================] - 68s 248ms/step - loss: 0.4410 - acc: 0.8007 - val_loss: 0.4304 - val_acc: 0.8025\n",
      "Epoch 3/5\n",
      " 11/274 [>.............................] - ETA: 1:31 - loss: 0.3174 - acc: 0.8778"
     ]
    }
   ],
   "source": [
    "models_info = {}\n",
    "set_random_seed(42)\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\nStart learning model: {model.name}\\n\")\n",
    "    model.build.summary()\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.build.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.3,\n",
    "        verbose=1,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Додаємо історію, та час навчання до словника\n",
    "    models_info.setdefault(model.name, {})[\"history\"] = history\n",
    "    models_info[model.name][\"edu_time\"] = round(end_time - start_time, 2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_loss, test_acc = model.build.evaluate(x_test, y_test)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Визначаємо функцію втрат та точність на тестових даних\n",
    "    print(f\"Test Loss: {test_loss:.2f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "    models_info[model.name][\"test_loss\"] = round(test_loss, 2)\n",
    "    models_info[model.name][\"test_acc\"] = round(test_acc, 2)\n",
    "    models_info[model.name][\"eval_time\"] = round(end_time - start_time, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Підсумки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Візуалізація кривих навчання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    len(models_info) // 2, 2, figsize=(15, 4 * (len(models_info) // 2)), sharex=True\n",
    ")\n",
    "\n",
    "for i, (model_name, model_info) in enumerate(models_info.items()):\n",
    "    history = model_info[\"history\"]\n",
    "\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "\n",
    "    ax1 = axs[row, col]\n",
    "\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_accuracy = history.history[\"val_acc\"]\n",
    "    accuracy = history.history[\"acc\"]\n",
    "\n",
    "    ax1.plot(val_accuracy, label=\"Validation Accuracy\", marker=\"o\", color=\"r\")\n",
    "    ax1.plot(accuracy, label=\"Accuracy\", color=\"r\", alpha=0.5)\n",
    "    ax1.fill_between(\n",
    "        range(len(accuracy)), accuracy, val_accuracy, color=\"orange\", alpha=0.2\n",
    "    )\n",
    "    ax1.tick_params(labelcolor=\"k\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\", color=\"r\")\n",
    "\n",
    "    for j, acc in enumerate(val_accuracy):\n",
    "        ax1.annotate(\n",
    "            f\"{acc:.2f}\",\n",
    "            (j, acc),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(0, -15),\n",
    "            ha=\"center\",\n",
    "            c=\"r\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax2.plot(val_loss, label=\"Validation Loss\", marker=\"o\", color=\"b\", alpha=0.1)\n",
    "    ax2.plot(loss, label=\"Loss\", color=\"b\", alpha=0.1)\n",
    "    ax2.set_ylabel(\"Loss Function\", color=\"b\", alpha=0.5)\n",
    "    ax2.fill_between(range(len(loss)), loss, val_loss, alpha=0.1)\n",
    "\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"r\")\n",
    "    ax2.grid(True, linestyle=\"--\")\n",
    "\n",
    "    ax2.legend(loc=\"lower left\")\n",
    "\n",
    "    plt.grid()\n",
    "    plt.title(f\"Криві навчання {model_name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"training_curves_epochs_{epochs}_batch_{batch_size}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наведемо підсумкові дані до таблиці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(models_info)\n",
    "\n",
    "# Deleting the column 'history'\n",
    "df = df.drop(\n",
    "    \"history\",\n",
    "    axis=0,\n",
    ").transpose()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data_epochs_{epochs}_batch_{batch_size}.csv\", index=True, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Візуалізуємо ці результати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "df[\"edu_time\"].plot(kind=\"bar\", ax=ax1, position=1, color=\"b\", width=0.4)\n",
    "ax1.set_ylabel(\"Education Time (s)\", color=\"b\")\n",
    "ax1.tick_params(\"y\", colors=\"b\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "df[\"test_acc\"].plot(kind=\"bar\", ax=ax2, position=0, color=\"r\", width=0.4)\n",
    "df[\"test_loss\"].plot(kind=\"line\", ax=ax2, color=\"g\", linestyle=\"--\", marker=\"o\")\n",
    "\n",
    "ax2.set_ylabel(\"Test Loss / Test Accuracy\", color=\"r\")\n",
    "ax2.tick_params(\"y\", colors=\"r\")\n",
    "ax1.set_xticklabels(df.index, rotation=45)\n",
    "plt.title(\"Порівняння моделей\")\n",
    "plt.legend([\"Test Loss\", \"Test Accuracy\"], loc=\"upper right\")\n",
    "plt.savefig(f\"model_comparison_epochs_{epochs}_batch_{batch_size}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "all_predictions = []\n",
    "for model in models:\n",
    "    y_pred = model.build.predict(x_test)\n",
    "    y_pred = y_pred > 0.5\n",
    "    all_predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создать общую фигуру\n",
    "fig, axs = plt.subplots(1, len(models), figsize=(15, 3), squeeze=False)\n",
    "\n",
    "# Вычислить и отобразить матрицы ошибок для каждой модели\n",
    "for i, model in enumerate(models):\n",
    "    cm = confusion_matrix(y_test, all_predictions[i])\n",
    "\n",
    "    df1 = pd.DataFrame(columns=[\"True\", \"False\"], index=[\"True\", \"False\"], data=cm)\n",
    "\n",
    "    sns.heatmap(df1, annot=True, cmap=\"Blues\", fmt=\".0f\", ax=axs[0, i])\n",
    "    axs[0, i].set_xlabel(\"Predicted Label\")\n",
    "    axs[0, i].tick_params(axis=\"x\", labelsize=12)\n",
    "    axs[0, i].tick_params(axis=\"y\", labelsize=12, rotation=0)\n",
    "    axs[0, i].set_ylabel(\"True Label\")\n",
    "    axs[0, i].set_title(f\"Confusion Matrix for {model.name}\", size=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"convolution_matrix_epochs_{epochs}_batch_{batch_size}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Висновки\n",
    "\n",
    "Експерименти проводились для кількості епох: 5, 10 та 15.\n",
    "\n",
    "При навчанні у 15 епох, вже починаючи з 5-ї спостерігаєтся перенавчання\n",
    "\n",
    "В рамках експеременту найефективніше себе показали 5 епох\n",
    "\n",
    "| Model              | edu_time | test_loss | test_acc |\n",
    "|--------------------|----------|-----------|----------|\n",
    "| SRNN               | 182.65   | 0.49      | 0.81     |\n",
    "| Bidirectional_SRNN | 304.76   | 0.47      | 0.79     |\n",
    "| LSTM               | 544.57   | 0.32      | 0.87     |\n",
    "| Bidirectional_LSTM | 1129.91  | 0.32      | 0.87     |\n",
    "\n",
    "\n",
    "Для простих архітектур RNN цього достатньо для наступних висновків:\n",
    "\n",
    "1.Хоча і магають більше часу на навчанння, але Моделі LSTM показують крашу точність ніж прості рекурентні мережі SimpleRNN. \n",
    "\n",
    "   \n",
    "2. Однонаправлені моделі мають кращі результатти ніж дво направлені. Крім того, вони вимагають менше часу навчання, але припускаю що це може змінюватись у контексті цільового використання, наприклад в задачах машинного перекладу такий підхід описуєтся, як кращий.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
